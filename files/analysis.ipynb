{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "''' GENERAL '''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import re\n",
    "\n",
    "''' ANALYSIS '''\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "''' VISUALISATION '''\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def write_table(table, name, caption, label, dec=None, sig_note=False, index=True):\n",
    "    if dec:\n",
    "        dec = f'%.{dec}f'\n",
    "\n",
    "    table_latex = table.to_latex(caption=caption, label='tab:' + label, float_format=dec, index=index)\n",
    "    table_latex = table_latex.replace('\\\\begin{table}\\n', '\\\\begin{table}\\n\\\\centering\\n')\n",
    "\n",
    "    sig_note_str = '''\\\\bottomrule\n",
    "\\\\addlinespace[1ex]\n",
    "\\\\multicolumn{3}{l}\n",
    "    {\n",
    "        \\\\textsuperscript{***}$p<0.01$,\n",
    "        \\\\textsuperscript{**}$p<0.05$,\n",
    "        \\\\textsuperscript{*}$p<0.1$\n",
    "    }'''\n",
    "\n",
    "    if sig_note:\n",
    "        table_latex = table_latex.replace('\\\\bottomrule', sig_note_str)\n",
    "\n",
    "    with open(f'../tables/{name}.tex', 'w') as out:\n",
    "        out.write(table_latex)\n",
    "\n",
    "    print(table_latex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def add_sigs(val):\n",
    "    if val <= 0.01:\n",
    "        return str(val) + '***'\n",
    "    elif 0.01 < val <= 0.05:\n",
    "        return str(val) + '**'\n",
    "    elif 0.05 < val <= 0.1:\n",
    "        return str(val) + '*'\n",
    "    else:\n",
    "        return str(val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "''' COUNTS '''\n",
    "\n",
    "sim_occ = pd.read_csv('sim_occ_level_3.csv', dtype={'sim_occ': 'str'})\n",
    "counts_long = pd.DataFrame(sim_occ.groupby('app_year', as_index=False)['sim_occ'].value_counts())\n",
    "\n",
    "def rel_count(row, nr_patents):\n",
    "    count = row['count']\n",
    "    year = row['app_year']\n",
    "    total = nr_patents.loc[nr_patents['app_year'] == year, 'count'].iloc[0]\n",
    "\n",
    "    return (count / total) * 100\n",
    "\n",
    "patents_per_year = pd.DataFrame(sim_occ['app_year'].value_counts())\n",
    "patents_per_year = patents_per_year.sort_values('app_year', axis=0).reset_index()\n",
    "\n",
    "counts_long['count_rel'] = counts_long.apply(lambda x: rel_count(x, patents_per_year), axis=1)\n",
    "\n",
    "counts_wide = counts_long.query(\"2009 <= app_year <= 2020\")\n",
    "counts_wide = counts_wide.pivot(columns='sim_occ', index='app_year', values='count')\n",
    "counts_wide.columns.name = None\n",
    "counts_wide.index.name = None\n",
    "counts_wide = counts_wide.fillna(0)\n",
    "counts_wide = counts_wide.astype('int')\n",
    "\n",
    "counts_total = counts_long.groupby('sim_occ')['count'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "''' LABOR FORCE SURVEY '''\n",
    "# Labour force survey\n",
    "lfs_long = pd.read_csv('lfs.csv', dtype={'ISCO3D': 'str'})\n",
    "lfs_long.rename({'nuts': 'nuts_code', 'ISCO3D': 'isco_code', 'NACE1D': 'nace_code'}, axis=1, inplace=True)\n",
    "\n",
    "lfs_long['nuts_code'] = lfs_long['nuts_code'].apply(lambda x: x[:2])\n",
    "lfs_long = lfs_long.groupby(['nuts_code', 'year', 'isco_code'], as_index=False)['n'].sum()\n",
    "\n",
    "# Add 0 to military isco codes: \"21\" --> \"021\"\n",
    "lfs_long['isco_code'] = np.select(\n",
    "    condlist=[\n",
    "        lfs_long['isco_code'].apply(lambda x: len(x) == 2),\n",
    "        lfs_long['isco_code'].apply(lambda x: len(x) == 1)\n",
    "    ],\n",
    "    choicelist=[\n",
    "        lfs_long['isco_code'].apply(lambda x: '0' + x),\n",
    "        lfs_long['isco_code'].apply(lambda x: '00' + x),\n",
    "    ],\n",
    "    default=lfs_long['isco_code']\n",
    ")\n",
    "lfs_long.set_index(['nuts_code', 'year'], inplace=True)\n",
    "\n",
    "lfs_na = ['BG', 'MT', 'PL', 'SI', 'SK'] # Countries with missing lfs data\n",
    "lfs_long = lfs_long.drop(lfs_na)\n",
    "\n",
    "''' pivot '''\n",
    "\n",
    "lfs_wide = lfs_long.pivot_table(index=['nuts_code', 'year'], columns='isco_code', values='n')\n",
    "lfs_wide = lfs_wide.fillna(0)\n",
    "lfs_wide =  lfs_wide.astype('int')\n",
    "\n",
    "lfs_wide = lfs_wide.reset_index()\n",
    "lfs_wide.set_index(['nuts_code', 'year'], inplace=True)\n",
    "lfs_wide.columns.name = None\n",
    "\n",
    "lfs_wide = lfs_wide.drop(columns=[c for c in lfs_wide.columns if not c in counts_wide.columns])\n",
    "\n",
    "''' aggregated '''\n",
    "\n",
    "lfs_wide_eu = lfs_wide.groupby('year').mean()\n",
    "# lfs_wide_eu['nuts_code'] = 'EU'\n",
    "# lfs_wide_eu =lfs_wide_eu.set_index('nuts_code', append=True)\n",
    "# lfs_wide_eu = lfs_wide_eu.reorder_levels(['nuts_code', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "''' RENEWABLE ENERGY '''\n",
    "\n",
    "ren_energy_wide = pd.read_csv('estat_nrg_ind_ren.tsv', sep='\\t')\n",
    "\n",
    "ren_energy_cols = ['freq', 'nrg_bal', 'unit', 'geo']\n",
    "ren_energy_wide[ren_energy_cols] = ren_energy_wide.iloc[:, 0].str.split(',', expand=True)\n",
    "\n",
    "ren_energy_cols = ren_energy_wide.columns.tolist()\n",
    "ren_energy_cols = ren_energy_cols[-4:] + ren_energy_cols[1:-4]\n",
    "ren_energy_cols = ren_energy_cols[3:]\n",
    "\n",
    "ren_energy_wide = ren_energy_wide.loc[ren_energy_wide['nrg_bal'] == 'REN', ren_energy_cols]\n",
    "\n",
    "ren_energy_wide.columns = [int(c) if not c.isalpha() else c for c in ren_energy_wide.columns]\n",
    "ren_energy_wide.replace(': ', np.nan, inplace=True)\n",
    "\n",
    "ren_energy_wide[ren_energy_wide.columns[1:]] = ren_energy_wide[ren_energy_wide.columns[1:]].astype('float')\n",
    "\n",
    "# ren_energy.drop(ren_energy[ren_energy['geo'].isin(['GE', 'BA'])].index, inplace=True)\n",
    "ren_energy_wide.reset_index(drop=True, inplace=True)\n",
    "ren_energy_wide.rename(columns={'geo': 'nuts_code'}, inplace=True)\n",
    "\n",
    "ren_energy_wide.drop(columns=range(2004, 2013), inplace=True)\n",
    "ren_energy_wide.drop(columns=range(2021, 2023), inplace=True)\n",
    "\n",
    "ren_energy_wide = ren_energy_wide.set_index('nuts_code')\n",
    "# ren_energy.drop('EU27_2020', inplace=True)\n",
    "\n",
    "ren_energy_long = ren_energy_wide.reset_index().melt(id_vars=['nuts_code'], var_name='year', value_name='ren_energy').sort_values(['nuts_code', 'year']).set_index(['nuts_code', 'year'])\n",
    "\n",
    "ren_energy_long_eu = ren_energy_long.loc['EU27_2020']\n",
    "scaler = StandardScaler()\n",
    "ren_energy_long_eu_s = pd.DataFrame(scaler.fit_transform(ren_energy_long_eu))\n",
    "ren_energy_long_eu_s.index = range(2013, 2021)\n",
    "ren_energy_long_eu_s.columns = ['ren_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ren_idx = set(ren_energy_long.index.levels[0])\n",
    "lfs_idx = set(lfs_wide.index.levels[0])\n",
    "\n",
    "ren_energy_long.drop(list(ren_idx - lfs_idx), inplace=True)\n",
    "lfs_wide.drop(list(lfs_idx - ren_idx), inplace=True)\n",
    "lfs_long.drop(list(lfs_idx - ren_idx), inplace=True)\n",
    "\n",
    "ren_energy_long.index = ren_energy_long.index.remove_unused_levels()\n",
    "lfs_wide.index = lfs_wide.index.remove_unused_levels()\n",
    "lfs_long.index = lfs_long.index.remove_unused_levels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "''' R&D '''\n",
    "\n",
    "rd_data = pd.read_csv('COUNTRY_BUDGETS_SUMMARY.csv', sep=';', header=4)\n",
    "rd_data = rd_data.replace('..', np.nan)\n",
    "rd_data['VALUE'] = rd_data['VALUE'].astype('float')\n",
    "rd_data = rd_data.query(\"PRODUCT == 'RDDEURO' and (2013 <= TIME <= 2020) and FLOW == 'TOTAL'\")\n",
    "rd_data = rd_data[['TIME', 'COUNTRY', 'VALUE']]\n",
    "rd_data.columns = ['year', 'nuts_code', 'rnd']\n",
    "rd_data = rd_data.sort_values('nuts_code')\n",
    "rd_data = rd_data.set_index(['nuts_code', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "''' ISCO '''\n",
    "\n",
    "# Read file\n",
    "isco = pd.read_excel('isco.xlsx', dtype={'ISCO 08 Code': 'str'})\n",
    "# Rename columns\n",
    "isco.rename(columns={'Level': 'isco_level', 'ISCO 08 Code': 'isco_code', 'Title EN': 'isco_title', 'Tasks include': 'isco_tasks', 'Definition': 'isco_definition'}, inplace=True)\n",
    "# Drop unnecessary columns\n",
    "isco = isco.iloc[:, :5]\n",
    "# Add '0'/'00' to level 1/2 isco codes ('21' --> '210', '8' --> '800')\n",
    "isco['isco_code'] = np.select(\n",
    "    condlist=[\n",
    "        isco['isco_level'] == 1,\n",
    "        isco['isco_level'] == 2\n",
    "    ],\n",
    "    choicelist=[\n",
    "        isco['isco_code'].apply(lambda x: x + '00'),\n",
    "        isco['isco_code'].apply(lambda x: x + '0'),\n",
    "    ],\n",
    "    default=isco['isco_code']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "''' Variance Inflation Factor '''\n",
    "\n",
    "# Calculate VIF for each independent variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = lfs_wide.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(lfs_wide.values, i) for i in range(len(lfs_wide.columns))]\n",
    "\n",
    "# vif_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def weight_with_patent_lag(x:\"pd.Series\", counts:\"Wide\"):\n",
    "        # Series as float\n",
    "        x = x.astype('float')\n",
    "        # Iterate over series\n",
    "        for year in x.index:\n",
    "            # LFS value for year y\n",
    "            lfs_val = x.loc[year]\n",
    "            # Lagged sum of occupation\n",
    "            sum_ = counts.loc[year-4:year, x.name].sum()\n",
    "            # Lagged total amount of occupations\n",
    "            total = counts.loc[year-4:year].sum(axis=1).sum()\n",
    "            # Sum of occupation relative to total\n",
    "            rel = sum_/total\n",
    "            # Assign relative value to x\n",
    "            x.loc[year] = lfs_val * rel\n",
    "\n",
    "        return x\n",
    "\n",
    "def scale_and_weight(lfs:\"Series wide\"):\n",
    "    scaler = StandardScaler()\n",
    "    lfs_scaled = lfs.copy().astype('float')\n",
    "    lfs_scaled.loc[:, :] = scaler.fit_transform(lfs)\n",
    "    lfs_scaled_weighted = lfs_scaled.apply(lambda x: weight_with_patent_lag(x, counts_wide), axis=0)\n",
    "\n",
    "    return lfs_scaled_weighted\n",
    "\n",
    "def optimal_nr_comp(lfs: \"Wide\", ren_energy: \"Long\"):\n",
    "    n_components = min(lfs.shape)\n",
    "    mse_scores = []\n",
    "\n",
    "    # Perform PCA and cross-validation for each number of components\n",
    "    for n in range(1, n_components + 1):\n",
    "        pca = PCA(n_components=n)\n",
    "        X_pca = pca.fit_transform(lfs)\n",
    "\n",
    "        model = LinearRegression()\n",
    "        scores = cross_val_score(model, X_pca, ren_energy, cv=5, scoring='neg_mean_squared_error')\n",
    "        mse_scores.append(-scores.mean())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Plot the MSE scores\n",
    "    plt.plot(range(1, n_components + 1), mse_scores, marker='o')\n",
    "    plt.xlabel('Number of Principal Components')#, fontsize=16)\n",
    "    plt.ylabel('Mean Squared Error')#, fontsize=16)\n",
    "    plt.tick_params(axis='both')#, labelsize=14)  # Change the font size for major ticks\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    pca = PCA().fit(lfs)\n",
    "    plt.plot(pd.DataFrame(np.cumsum(pca.explained_variance_ratio_), index=range(1,8)))\n",
    "    plt.xlabel('Number of Components')#, fontsize=16)\n",
    "    plt.ylabel('Cumulative Explained Variance')#, fontsize=16)\n",
    "    plt.tick_params(axis='both')#, labelsize=14)  # Change the font size for major ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "''' OLS ANALYSIS '''\n",
    "\n",
    "def ols_pca(lfs, ren_energy, rd_data):\n",
    "    # Init scaler object\n",
    "    scaler = StandardScaler()\n",
    "    # Scale and weight lfs data\n",
    "    lfs_transformed = scale_and_weight(lfs)\n",
    "    # Create principal components with given n components\n",
    "    pca = PCA(n_components=1)\n",
    "    components = pca.fit_transform(lfs_transformed)\n",
    "    # Scale R&D data\n",
    "    rd_scaled = scaler.fit_transform(rd_data)\n",
    "    # Scale renewable energy data\n",
    "    ren_energy_scaled = scaler.fit_transform(ren_energy)\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(components)\n",
    "    df['R&D'] = rd_scaled\n",
    "    df['ren_energy'] = ren_energy_scaled\n",
    "    df.index = range(2013,2021)\n",
    "    cols = df.columns.tolist()\n",
    "    cols[0] = 'PC'\n",
    "    df.columns = cols\n",
    "\n",
    "    df = df.drop(2013)\n",
    "\n",
    "    X = df.drop(columns='ren_energy')\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    Y = df['ren_energy']\n",
    "\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "cols = [c for c in lfs_wide.columns if re.match('7..', c)]\n",
    "lfs_wide_sig = lfs_wide[cols]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "pvals_df = pd.DataFrame()\n",
    "models = {}\n",
    "countries = lfs_wide.index.levels[0]\n",
    "\n",
    "for c in countries:\n",
    "    model = ols_pca(lfs_wide_sig.loc[c],\n",
    "                    rd_data.loc['EU'],\n",
    "                    ren_energy_long.loc[c])\n",
    "\n",
    "    models[c] = model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "df_ols = pd.DataFrame()\n",
    "for c in models.keys():\n",
    "    df = pd.DataFrame()\n",
    "    model = models[c]\n",
    "    df['coef'] = model.params\n",
    "    df['std err'] = model.bse\n",
    "    df['t'] = model.tvalues\n",
    "    df['p-value'] = model.pvalues\n",
    "    df.index.name = 'stats'\n",
    "    df['country'] = c\n",
    "    df = df.set_index('country', append=True)\n",
    "    df = df.reorder_levels(['country', 'stats'])\n",
    "    df_ols = pd.concat([df_ols, df])\n",
    "\n",
    "df_ols = df_ols.apply(lambda x: round(x, 4))\n",
    "df_ols['p-value'] = df_ols['p-value'].apply(add_sigs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# write_table(df_ols[36:], 'ols_eu', 'Regression results per country', 'ols_eu', index=True, dec=4, sig_note=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{ISCO Titles (Top 30 recurring occupations}\n",
      "\\label{tab:isco_def}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "ISCO Code & Definition \\\\\n",
      "\\midrule\n",
      "211 & Physical and Earth Science Professionals \\\\\n",
      "212 & Mathematicians, Actuaries and Statisticians \\\\\n",
      "215 & Electrotechnology Engineers \\\\\n",
      "226 & Other Health Professionals \\\\\n",
      "251 & Software and Applications Developers and Analysts \\\\\n",
      "311 & Physical and Engineering Science Technicians \\\\\n",
      "313 & Process Control Technicians \\\\\n",
      "314 & Life Science Technicians and Related Associate Professionals \\\\\n",
      "352 & Telecommunications and Broadcasting Technicians \\\\\n",
      "711 & Building Frame and Related Trades Workers \\\\\n",
      "712 & Building Finishers and Related Trades Workers \\\\\n",
      "713 & Painters, Building Structure Cleaners and Related Trades Workers \\\\\n",
      "721 & Sheet and Structural Metal Workers, Moulders and Welders, and Related Workers \\\\\n",
      "731 & Handicraft Workers \\\\\n",
      "732 & Printing Trades Workers \\\\\n",
      "741 & Electrical Equipment Installers and Repairers \\\\\n",
      "742 & Electronics and Telecommunications Installers and Repairers \\\\\n",
      "751 & Food Processing and Related Trades Workers \\\\\n",
      "752 & Wood Treaters, Cabinet-makers and Related Trades Workers \\\\\n",
      "754 & Other Craft and Related Workers \\\\\n",
      "812 & Metal Processing and Finishing Plant Operators \\\\\n",
      "813 & Chemical and Photographic Products Plant and Machine Operators \\\\\n",
      "814 & Rubber, Plastic and Paper Products Machine Operators \\\\\n",
      "815 & Textile, Fur and Leather Products Machine Operators \\\\\n",
      "816 & Food and Related Products Machine Operators \\\\\n",
      "817 & Wood Processing and Papermaking Plant Operators \\\\\n",
      "818 & Other Stationary Plant and Machine Operators \\\\\n",
      "821 & Assemblers \\\\\n",
      "834 & Mobile Plant Operators \\\\\n",
      "912 & Vehicle, Window, Laundry and Other Hand Cleaning Workers \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "isco_def_table = isco[isco['isco_code'].isin(counts_total.index[:30])][['isco_code', 'isco_title']]\n",
    "isco_def_table.columns = ['ISCO Code', 'Definition']\n",
    "write_table(isco_def_table, 'isco_def', 'ISCO Titles (Top 30 recurring occupations', 'isco_def', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
